"""
NetCDF Writer Module for ESA CCI Sea Ice Concentration Products

This module provides CF-1.7 compliant NetCDF file creation for EASE2 gridded
sea ice concentration data from NEMS.
"""

import os
import uuid
import datetime
import numpy as np
import xarray as xr


def makeNetCDF(data_vars, date, hemisphere, area_def, save_dir):
    """
    Write one EASE2 NetCDF file with full CF-1.7 compliance.

    Parameters
    ----------
    data_vars : dict
        Required keys and expected content:

        Concentration / uncertainty (float32, range [0, 1] — scaled ×100 here):
            ice_conc, raw_ice_conc_values,
            total_standard_error, smearing_standard_error,
            algorithm_standard_error

        Status flag (int32):
            status_flag

        Brightness temperatures (float32, Kelvin, shape (H, W)):
            tb_22          – raw measured Tb at 22 GHz
            tb_31          – raw measured Tb at 31 GHz
            tb_22_corr     – atmospheric-corrected Tb at 22 GHz
            tb_31_corr     – atmospheric-corrected Tb at 31 GHz

    date : str  'YYYY-MM-DD'
    hemisphere : str  'N' or 'S'
    area_def : pyresample.geometry.AreaDefinition
    save_dir : str
    
    Returns
    -------
    str
        Path to the created NetCDF file
    """
    year  = date[:4]
    month = date[5:7]
    day   = date[8:10]

    ncfile_n    = ("ESACCI-SEAICE-L3C-SICONC-NIMBUS5_NEMS-EASE2_%sH-%s%s%s-fv1.1.nc"
                   % (hemisphere, year, month, day))
    ncfile_path = os.path.join(save_dir, ncfile_n)

    # Convert fractions to percentages (operates on the copies passed in by
    # create_NetCDF, so the caller's arrays are never modified).
    for pct_var in ('ice_conc', 'smearing_standard_error', 'algorithm_standard_error',
                    'total_standard_error', 'raw_ice_conc_values'):
        data_vars[pct_var] *= 100

    # Grid dimensions
    area_h, area_w = area_def.shape   # (rows, cols)

    # Reshape all 2-D (H, W) arrays → (1, H, W)  dims: [time, yc, xc]
    for var, arr in data_vars.items():
        if isinstance(arr, tuple):
            continue          # already wrapped (e.g. time_bnds added below)
        arr = np.asarray(arr)
        if arr.ndim == 2:
            data_vars[var] = (["time", "yc", "xc"],
                              arr.reshape((1, area_h, area_w)))

    # Time bounds
    time_bnds_ = np.array([[datetime.datetime(int(year), int(month), int(day), 0, 0),
                            datetime.datetime(int(year), int(month), int(day), 0, 0)
                            + datetime.timedelta(days=1)]]).astype('datetime64[ns]')

    data_vars['Lambert_Azimuthal_Grid'] = np.array(-2147483647, dtype='int32')
    data_vars['time_bnds'] = (["time", "nv"], time_bnds_)

    # Metadata helpers
    lonss, latss = area_def.get_lonlats()
    today        = datetime.datetime.now().strftime("%Y-%m-%dT%H:%M:%S")
    today_date   = datetime.datetime.now().strftime("%Y-%m-%d")
    trackid      = uuid.uuid4()

    coords = dict(time=[np.array(year + '-' + month + '-' + day + 'T12:00:00.000000000').astype('datetime64[ns]')],
                        xc=area_def.projection_x_coords / 1000,
                        yc=area_def.projection_y_coords / 1000,
                        lat=(["yc", "xc"], latss.astype(np.float32)),
                        lon=(["yc", "xc"], lonss.astype(np.float32)),)

    attrs = dict(description="Weather related data.",
                 
                 title='Sea Ice Concentration Climate Data Record from ESA Climate Change Initiative',
                 
                 summary=('This climate data record of sea ice concentration is obtained from passive '
                        'microwave satellite data over the polar regions (NEMS). The processing chain '
                        'features: 1) dynamic tuning of tie-points and algorithms, 2) correction of '
                        'atmospheric noise using a Radiative Transfer Model, 3) computation of '
                        'per-pixel uncertainties, and 4) hybrid sea ice concentration algorithm. '
                        'This dataset was generated by the ESA Climate Change Initiative.'),
                 topic_category='Oceans Climatology Meteorology Atmosphere',
                 
                 keywords=('Earth Science > Cryosphere > Sea Ice > Sea Ice Concentration, '
                           'Earth Science > Oceans > Sea Ice > Sea Ice Concentration, '
                           'Earth Science > Climate Indicators > Cryospheric Indicators > Sea Ice Concentration'),
                 keywords_vocabulary='GCMD Science Keywords',
        
                geospatial_lat_min=float(np.min(latss)),
                geospatial_lat_max=float(np.max(latss)),
                geospatial_lon_min=float(np.min(lonss)),
                geospatial_lon_max=float(np.max(lonss)),
                geospatial_vertical_min=0.0,
                geospatial_vertical_max=0.0,
                sensor='NEMS',
                platform='Nimbus-5',
                source='NEMS from Nimbus 5, ERA-5 fields from ECMWF',
                time_coverage_start=f'{year}-{month}-{day}T00:00:00Z',
                time_coverage_end=f'{year}-{month}-{day}T23:59:59Z',
                time_coverage_duration='P1D',
                time_coverage_resolution='P1D',
                project='ESA Climate Change Initiative',
                institution='ESA Climate Change Initiative',
                creator_name='DTU Space',
                creator_type='institution',
                creator_url='https://www.space.dtu.dk/',
        
                license=("All intellectual property rights of the ESA Climate Change Initiative products "
                         "belong to ESA. The use of these products is granted to every user, free of charge. "
                         "If users wish to use these products, ESA's copyright credit must be shown by "
                         "displaying the words 'Copyright ESA' under each of the products shown. ESA offers "
                         "no warranty and accepts no liability. ESA neither commits to nor guarantees the "
                         "continuity, availability, or quality or suitability for any purpose."),
                
                references='https://climate.esa.int/en/projects/sea-ice/Sea-Ice-Key-Documents/',
                history=f'{today}Z creation',
                date_created=today_date,
                cdm_data_type='Grid',
                spatial_resolution='25.0 km',
                geospatial_bounds_crs='EPSG:6931' if hemisphere == 'N' else 'EPSG:6932',
                contributor_name=('Rasmus Tonboe, Wiebke Margitta Kolbe,'
                                  'Emil Haaber Tellefsen, Ida Grum-Schwensen Andersen'),
                contributor_role=('Principal Investigator, Co-Investigator, author, author'),
                product_version='1.1',
                tracking_id=str(trackid),
                naming_authority='esa.int',
                Conventions='CF-1.7, ACDD-1.3',
                standard_name_vocabulary='CF Standard Name Table v92',)

    dNN = xr.Dataset(data_vars, coords, attrs)

    # coordinate attributes
    dNN.time.attrs.update({'long_name': 'reference time of product',
                           'standard_name': 'time',
                           'axis': 'T',
                           'bounds': 'time_bnds',})
    
    dNN.time.encoding['units']      = "days since 1900-01-01T00:00:00"
    dNN.time.encoding['calendar']   = "gregorian"
    dNN.time_bnds.encoding['units'] = "days since 1900-01-01T00:00:00"
    dNN.time_bnds.encoding['calendar'] = "gregorian"

    dNN.lon.attrs.update({'units': 'degrees_east',
                          'long_name': 'longitude coordinate',
                          'standard_name': 'longitude',})
    
    dNN.lat.attrs.update({'units': 'degrees_north',
                          'long_name': 'latitude coordinate',
                          'standard_name': 'latitude',})
    
    dNN.xc.attrs.update({'units': 'km',
                        'long_name': 'x coordinate of projection (eastings)',
                        'standard_name': 'projection_x_coordinate',
                        'axis': 'X',})
    
    dNN.yc.attrs.update({'units': 'km',
                         'long_name': 'y coordinate of projection (northings)',
                         'standard_name': 'projection_y_coordinate',
                         'axis': 'Y', })

    # ---------- grid mapping ----------
    dNN.Lambert_Azimuthal_Grid.attrs.update({
        'grid_mapping_name':              'lambert_azimuthal_equal_area',
        'longitude_of_projection_origin': float(area_def.proj_dict['lon_0']),
        'latitude_of_projection_origin':  float(area_def.proj_dict['lat_0']),
        'false_easting':                  0.0,
        'false_northing':                 0.0,
        'semi_major_axis':                6378137.0,
        'semi_minor_axis':                6356752.314245,
        'inverse_flattening':             298.257223563,
    })

    # ---------- SIC variable attributes ----------
    dNN.ice_conc.attrs.update({
        'long_name':           ('sea ice concentration'),
        'standard_name':       'sea_ice_area_fraction',
        'units':               'percent',
        'valid_min':           np.float32(0),
        'valid_max':           np.float32(100),
        'grid_mapping':        'Lambert_Azimuthal_Grid',
        'coordinates':         'lat lon',
        'ancillary_variables': 'total_standard_error status_flag',
        'comment':             ('This field is the primary sea ice concentration estimate '
                                'for this climate data record. Fully filtered concentration '
                                'using atmospheric correction of brightness temperatures and '
                                'open water filters.'),
    })

    dNN.raw_ice_conc_values.attrs.update({
        'long_name':    ('unfiltered sea ice concentration'),
        'standard_name': 'sea_ice_area_fraction',
        'units':        'percent',
        'valid_min':    np.float32(-50),
        'valid_max':    np.float32(150),
        'grid_mapping': 'Lambert_Azimuthal_Grid',
        'coordinates':  'lat lon',
        'comment':      ('Sea ice concentration as retrieved by the algorithm, '
                         'before editing by the various filters. This field can be used '
                         'in combination with "ice_conc" to access the un-bounded distribution '
                         'of sea ice concentration estimates corresponding to the uncertainty '
                         'estimate in "total_standard_error". May contain unphysical values '
                         'below 0% or above 100%.'),
    })

    dNN.total_standard_error.attrs.update({
        'long_name':     ('total uncertainty (one standard deviation) of sea ice concentration'),
        'standard_name': 'sea_ice_area_fraction standard_error',
        'units':         'percent',
        'valid_min':     np.float32(0),
        'valid_max':     np.float32(100),
        'grid_mapping':  'Lambert_Azimuthal_Grid',
        'coordinates':   'lat lon',
        'comment':       ('Combined uncertainty from smearing and algorithm components.'),
    })

    dNN.smearing_standard_error.attrs.update({
        'long_name':    ('smearing uncertainty (one standard deviation) of sea ice concentration'),
        'standard_name': 'sea_ice_area_fraction standard_error',
        'units':        'percent',
        'valid_min':    np.float32(0),
        'valid_max':    np.float32(100),
        'grid_mapping': 'Lambert_Azimuthal_Grid',
        'coordinates':  'lat lon',
        'comment':      "One of the two components contributing to 'total_standard_error'. "
                        "Represents uncertainty due to spatial resolution effects.",
    })

    dNN.algorithm_standard_error.attrs.update({
        'long_name':    ('algorithm uncertainty (one standard deviation) of sea ice concentration'),
        'standard_name': 'sea_ice_area_fraction standard_error',
        'units':        'percent',
        'valid_min':    np.float32(0),
        'valid_max':    np.float32(100),
        'grid_mapping': 'Lambert_Azimuthal_Grid',
        'coordinates':  'lat lon',
        'comment':      "One of the two components contributing to 'total_standard_error'. "
                        "Represents uncertainty from the retrieval algorithm itself.",
    })

    dNN.status_flag.attrs.update({
        'long_name':         'status flag for sea ice concentration',
        'standard_name':     'sea_ice_area_fraction status_flag',
        'valid_min':         np.int32(0),
        'valid_max':         np.int32(255),
        'grid_mapping':      'Lambert_Azimuthal_Grid',
        'coordinates':       'lat lon',
        'flag_masks':        np.array([1, 2, 4, 8, 16, 32, 64, 128], dtype='int32'),
        'flag_meanings':     ('land lake open_water_filtered land_spillover '
                              'high_t2m coast maximum_ice_extent not_accepted'),
        'flag_descriptions': (
            'Bit-field status flag where multiple conditions can be true simultaneously. '
            'bit 0 (value 1): Position is over land; '
            'bit 1 (value 2): Position is over lake; '
            'bit 2 (value 4): Sea ice concentration set to zero by open water filter; '
            'bit 3 (value 8): Sea ice concentration modified to correct land spillover; '
            'bit 4 (value 16): High air temperature (t2m) detected; '
            'bit 5 (value 32): Coastal location; '
            'bit 6 (value 64): Outside climatological maximum ice extent; '
            'bit 7 (value 128): Retrieval not accepted, no other flags raised.'),
        'comment':           ('This is a bit-field flag. Multiple conditions can be true '
                              'simultaneously. To interpret: check individual bits using bitwise '
                              'operations. For example, flag value 80 (binary 01010000) means '
                              'bits 4 and 6 are set (high_t2m AND maximum_ice_extent).'),
    })

    # ---------- Brightness-temperature variable attributes ----------
    # CF-1.7 standard name: "toa_brightness_temperature"
    # TOA = top-of-atmosphere (i.e., measured at satellite sensor)

    _tb_shared = {'standard_name': 'toa_brightness_temperature',
                  'units': 'K',
                  'valid_min': np.float32(90.0),
                  'valid_max': np.float32(320.0),
                  'grid_mapping': 'Lambert_Azimuthal_Grid',
                  'coordinates': 'lat lon',}

    dNN.tb_22.attrs.update({**_tb_shared,
                            'long_name':     'brightness temperature at 22.235 GHz',
                            'sensor_band_central_radiation_frequency': '22.235 GHz',
                            'comment':       ('Measured (uncorrected) brightness temperature from the NEMS '
                                              '22.235 GHz channel.'),})

    dNN.tb_31.attrs.update({ **_tb_shared,
                            'long_name':     'brightness temperature at 31.4 GHz',
                            'sensor_band_central_radiation_frequency': '31.4 GHz',
                            'comment':       ('Measured (uncorrected) brightness temperature from the NEMS '
                                              '31.4 GHz channel.'),})

    dNN.tb_22_corr.attrs.update({**_tb_shared,
                                 'long_name':     'atmosphere-corrected brightness temperature at 22.235 GHz',
                                 'sensor_band_central_radiation_frequency': '22.235 GHz',
                                 'ancillary_variables': 'tb_22',
                                 'comment':       ('Brightness temperature from the NEMS 22.235 GHz channel '
                                                  'after RTM-based atmospheric path correction.'),})

    dNN.tb_31_corr.attrs.update({**_tb_shared,
                                'long_name':     'atmosphere-corrected brightness temperature at 31.4 GHz',
                                'sensor_band_central_radiation_frequency': '31.4 GHz',
                                'ancillary_variables': 'tb_31',
                                'comment':       ('Brightness temperature from the NEMS 31.4 GHz channel '
                                                  'after RTM-based atmospheric path correction.'),})

    # ---------- Encoding (compression + data types) ----------
    encoding = {'time_bnds':               {'_FillValue': None},
                'ice_conc':                {'zlib': True, 'complevel': 4, 'dtype': 'float32', '_FillValue': -999.0},
                'raw_ice_conc_values':     {'zlib': True, 'complevel': 4, 'dtype': 'float32', '_FillValue': -999.0},
                'total_standard_error':    {'zlib': True, 'complevel': 4, 'dtype': 'float32', '_FillValue': -999.0},
                'smearing_standard_error': {'zlib': True, 'complevel': 4, 'dtype': 'float32', '_FillValue': -999.0},
                'algorithm_standard_error':{'zlib': True, 'complevel': 4, 'dtype': 'float32', '_FillValue': -999.0},
                'tb_22':                   {'zlib': True, 'complevel': 4, 'dtype': 'float32', '_FillValue': -999.0},
                'tb_31':                   {'zlib': True, 'complevel': 4, 'dtype': 'float32', '_FillValue': -999.0},
                'tb_22_corr':              {'zlib': True, 'complevel': 4, 'dtype': 'float32', '_FillValue': -999.0},
                'tb_31_corr':              {'zlib': True, 'complevel': 4, 'dtype': 'float32', '_FillValue': -999.0},
                'status_flag':             {'dtype': 'int32', '_FillValue': -1},
                'Lambert_Azimuthal_Grid':  {'_FillValue': None},
                'lat':                     {'dtype': 'float32', '_FillValue': None},
                'lon':                     {'dtype': 'float32', '_FillValue': None},}

    dNN.to_netcdf(path=ncfile_path, mode='w', format='NETCDF4',
                  encoding=encoding,
                  unlimited_dims=['time'],)
    
    return ncfile_path


def create_NetCDF(data_vars, date, hemisphere, area_def, save_dir):
    """
    Validates data_vars, makes defensive copies (so the caller's arrays are
    not modified by the ×100 scaling inside makeNetCDF), then calls makeNetCDF.

    Parameters
    ----------
    data_vars : dict
        ice_conc, raw_ice_conc_values, total_standard_error,
        smearing_standard_error, algorithm_standard_error  → float32, range [0, 1]
        status_flag                                         → int32
        tb_22, tb_31, tb_22_corr, tb_31_corr               → float32, Kelvin,
                                                              shape (H, W)
    date : str  'YYYY-MM-DD'
    hemisphere : str  'N' or 'S'
    area_def : pyresample AreaDefinition
    save_dir : str
    
    Returns
    -------
    str
        Path to the created NetCDF file
    """
    required = ['ice_conc', 'raw_ice_conc_values',
                'total_standard_error', 'smearing_standard_error',
                'algorithm_standard_error', 'status_flag',
                'tb_22', 'tb_31', 'tb_22_corr', 'tb_31_corr',]

    missing = [k for k in required if k not in data_vars]
    if missing:
        raise ValueError(f"data_vars is missing required keys: {missing}")

    # Validate that all Tb variables are 2-D (H, W)
    for tb_var in ('tb_22', 'tb_31', 'tb_22_corr', 'tb_31_corr'):
        arr = np.asarray(data_vars[tb_var])
        if arr.ndim != 2:
            raise ValueError(f"'{tb_var}' must have shape (H, W) — got {arr.shape}.")

    # Create safe copies with proper dtypes
    float_vars = ['ice_conc', 'raw_ice_conc_values', 'total_standard_error',
                  'smearing_standard_error', 'algorithm_standard_error',
                  'tb_22', 'tb_31', 'tb_22_corr', 'tb_31_corr',]
    
    safe = {k: np.array(data_vars[k], dtype=np.float32).copy() for k in float_vars}
    safe['status_flag'] = np.array(data_vars['status_flag'], dtype=np.int32).copy()

    return makeNetCDF(safe, date, hemisphere, area_def, save_dir)


def make_status_flag(sic_grid, smask):
    """
    Derive a basic status_flag array from SIC values and the land/sea mask.
    
    Parameters
    ----------
    sic_grid : np.ndarray
        Sea ice concentration grid (H, W)
    smask : np.ndarray
        Land/sea mask (H, W) where 1=land, 2=lake
        
    Returns
    -------
    np.ndarray
        Status flag array (H, W) as int32
    """
    flag = np.zeros(sic_grid.shape, dtype=np.int32)
    flag[smask == 1]         = 1    # land
    flag[smask == 2]         = 2    # lake
    flag[np.isnan(sic_grid)] = 128  # not accepted / no data
    return flag